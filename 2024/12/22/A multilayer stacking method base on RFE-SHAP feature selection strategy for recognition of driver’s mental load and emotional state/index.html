<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state | There are issues still to be resolved</title><meta name="author" content="Gurongi"><meta name="copyright" content="Gurongi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="引文Huang, Jing, Yang Peng, and Lin Hu. “A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state.”Expert Systems with Applica"><meta property="og:type" content="article"><meta property="og:title" content="A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state"><meta property="og:url" content="https://superbangbangsugar.github.io/2024/12/22/A%20multilayer%20stacking%20method%20base%20on%20RFE-SHAP%20feature%20selection%20strategy%20for%20recognition%20of%20driver%E2%80%99s%20mental%20load%20and%20emotional%20state/index.html"><meta property="og:site_name" content="There are issues still to be resolved"><meta property="og:description" content="引文Huang, Jing, Yang Peng, and Lin Hu. “A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state.”Expert Systems with Applica"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://markdown.liuchengtu.com/work/uploads/upload_7c23db75dbf070c18ce49f88730a1aff.png"><meta property="article:published_time" content="2024-12-22T15:59:59.000Z"><meta property="article:modified_time" content="2024-12-23T02:14:47.728Z"><meta property="article:author" content="Gurongi"><meta property="article:tag" content="paper"><meta property="article:tag" content="model"><meta property="article:tag" content="traffic_risk"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://markdown.liuchengtu.com/work/uploads/upload_7c23db75dbf070c18ce49f88730a1aff.png"><link rel="shortcut icon" href="/"><link rel="canonical" href="https://superbangbangsugar.github.io/2024/12/22/A%20multilayer%20stacking%20method%20base%20on%20RFE-SHAP%20feature%20selection%20strategy%20for%20recognition%20of%20driver%E2%80%99s%20mental%20load%20and%20emotional%20state/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!0,top_n_per_article:1,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!0,islazyload:!1,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-12-23 10:14:47"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach(e=>{n.setAttribute(e,t[e])}),document.head.appendChild(n)}),e.getCSS=(e,t=!1)=>new Promise((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)}),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/menu_center.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2023/12/07/gbAJ49c5PmNiRUu.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">83</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">70</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 相册</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img fixed" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="There are issues still to be resolved"><img class="site-icon" src="https://s2.loli.net/2023/12/07/gbAJ49c5PmNiRUu.jpg"></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 相册</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-12-22T15:59:59.000Z" title="发表于 2024-12-22 23:59:59">2024-12-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-23T02:14:47.728Z" title="更新于 2024-12-23 10:14:47">2024-12-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%96%87%E7%8C%AE%E4%B8%8E%E9%98%85%E8%AF%BB/">文献与阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>18分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h1 id="引文"><a href="#引文" class="headerlink" title="引文"></a>引文</h1><p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S0957417423022315#s0065">Huang, Jing, Yang Peng, and Lin Hu. “A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state.”<em>Expert Systems with Applications</em>238 (2024): 121729.</a></p><h1 id="期刊"><a href="#期刊" class="headerlink" title="期刊"></a>期刊</h1><p>Expert Systems with Applications</p><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>The driver state monitoring is becoming one of the research hotspots in the field of traffic and vehicle safety, which can ensure driving safety by monitoring the driver’s state. Therefore, this work makes an attempt to recognize driver’s mental load and emotional states. However, the reliability and accuracy of driver status detection largely depend on the extracted features and the detection algorithm. The existing methods mainly improve accuracy by increasing the number of features, but for the problem with limited training samples, the increase in features may lead to an increase in model variance, and resulting in overfitting. In addition, single-model based methods may fall into local optimal solutions when performing local search. To alleviate these, we firstly propose an RFE-SHAP algorithm that improves the recursive feature elimination algorithm by using the Shapley Additive exPlanning value, and paired it with the eXtreme Gradient Boosting (XGBoost) algorithm to screen out the subset of features that best represent the driver’s mental load and emotional state. Secondly, we proposed a multilayer stacking ensemble learning method based on different optimal feature subsets to further improve the accuracy of the driver’s mental load and emotional state recognition. For each base models used for integration learning, the corresponding optimal feature subsets are selected using the RFE-SHAP algorithm, and then the different optimal feature subsets are combined with multilayer stacking ensemble learning. The validation via experimental data demonstrates that the XGBoost-RFE-SHAP algorithm achieves superior model performance with fewer feature combinations than the classic algorithm. The proposed driver state detection model based on multiple optimum feature subsets and multilayer stacking integration methods would more accurately identify the driver’s mental load and emotional state than the single model, commonly used machine learning and integrated learning algorithms.<br>驾驶员状态监测已成为交通与车辆安全领域研究的热点，通过监测驾驶员状态可以确保驾驶安全。因此，本工作尝试识别驾驶员的心理负荷和情绪状态。然而，驾驶员状态检测的可靠性和准确性很大程度上取决于提取的特征和检测算法。现有方法主要通过增加特征数量来提高准确性，但对于训练样本有限的问题，特征数量的增加可能会导致模型方差增加，并导致过拟合。此外，基于单模型的方法在进行局部搜索时可能会陷入局部最优解。为了解决这些问题，我们首先提出了一种 RFE-SHAP 算法，该算法通过使用 Shapley Additive exPlanning 值改进了递归特征消除算法，并与 eXtreme Gradient Boosting（XGBoost）算法配对，筛选出最能代表驾驶员心理负荷和情绪状态的特征子集。 其次，我们提出了一种基于不同最优特征子集的多层堆叠集成学习方法，以进一步提高驾驶员心理负荷和情绪状态识别的准确性。对于用于集成学习的每个基础模型，使用 RFE-SHAP 算法选择相应的最优特征子集，然后将不同的最优特征子集通过多层堆叠集成学习进行结合。通过实验数据验证表明，XGBoost-RFE-SHAP 算法在比经典算法更少的特征组合下实现了更好的模型性能。基于多个最优特征子集和多层堆叠集成方法的驾驶员状态检测模型相较于单一模型以及常用的机器学习和集成学习算法，能够更准确地识别驾驶员的心理负荷和情绪状态。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>世界卫生组织（WHO）的报告显示，全球道路交通死亡率为每 10 万人约 18 人死亡，不同地区之间存在差异，其中西太平洋地区的这一数字为每 10 万人 16.9 人死亡，东南亚地区为每 10 万人 20.7 人死亡（WHO，2020）。作为人类-车辆-道路道路交通系统的重要组成部分，驾驶员在交通安全中扮演着关键角色。交通管理部门追溯了 28,000 起交通事故的源头，并确定 96.4%的事故直接与人为因素有关，其中 74%是由于驾驶员操作失误所致（ JianBin，2012）。驾驶员的心理负荷和情绪状态是影响交通安全的主要变量之一（Ponte 和 Wundersitz，2019；Jeon，2017），在自然驾驶和自动驾驶接管等情况下，需要进行驾驶员状态检测以确保驾驶安全。<br>在过去的五年中，基于机器学习的驾驶员状态检测方法，如支持向量机 SVM（Chen 等，2020；Becerra-Sánchez 等，2020；Sowkarthika 等，2023），决策树 DT（Rahman 等，2021；Santos 等，2022），以及 K 近邻算法 KNN（Hao 等，2022；Nikolova 等，2018）算法，一直是研究的重点（Sikander 和 Anwar，2018；Dewangan 和 Purbey，2021；Abou Elassad 等，2020；Panicker 和 Gayathri，2019）。最近的工作比较研究见表 1。Mikhail Tokovarov（Magorzata，2019）使用 EEG 特征，通过这三种机器学习算法分别评估了驾驶员的多级认知负荷；研究结果表明，KNN 模型性能最佳，认知负荷检测准确率达到 91%。H Rahman（Rahman，2020）利用心率变异性及车辆运行数据，使用逻辑回归、支持向量机、线性判别分析 LDA 和神经网络四种算法构建了驾驶员心理负荷分类模型。 研究发现，开发的逻辑回归模型提供了最准确的预测，平均准确率为 94%。程文东等（程，2021）收集了驾驶员的眼动特征和头部摆动特征，并利用 D-S 证据理论构建了驾驶员分心状态识别方法；未佩戴眼镜的驾驶员分心状态识别准确率高达 86.2%。卡多内 D 等（卡多内，2022）基于驾驶模拟实验收集红外热信号和心电图数据，使用决策树、线性判别和支持向量机算法构建驾驶员负载分类模型，并比较发现使用多模态数据红外热图像+心率变异性作为特征输入时模型表现最佳。伊基尔沃斯 J（伊基尔沃斯，2018）基于 EEG 数据使用基于欧几里得距离的 K 近邻算法预测被试的情绪状态；所开发的模型准确率为 97%。程。 (程, 2019) 使用心电图(ECG)、心电图(ECG)和肌电图(EMG)的时间域特征训练了支持向量模型，测试集的平均准确率超过 80%。Cimtay Y 等(西姆泰, 2020) 使用脑电图输入和深度卷积神经网络 CNN 创建了一个情绪识别模型，二分类的准确率为 82.9%，三分类的准确率为 73.7%。Habibifar N(哈比比法尔, 2021) 收集了驾驶员的脑电图信号，并使用其频域特征作为模型输入，构建的神经网络(ANN)情绪分类模型的准确率达到了 95%。Gamage T 等(加马吉等, 2022) 从 10 名志愿者处收集了脑电图信号，并提取了相应的时域和频域特征，基于支持向量机算法训练分类模型，以识别驾驶员的悲伤、愤怒、恐惧和平静情绪状态。Mou L 等 (Mou, 2023) 提出了一种基于卷积长短期记忆网络（ConvLSTM）和混合注意力机制的多模态融合框架，用于融合车辆驾驶、眼动和环境数据，实验验证表明，在输入多模态数据时，该模型具有最佳的分类效果。</p><h2 id="Feature-selection"><a href="#Feature-selection" class="headerlink" title="Feature selection"></a>Feature selection</h2><p>有效的特征选择对于基于机器学习的驾驶员状态检测任务至关重要，删除无关和冗余特征可以提高模型的泛化性能同时减少计算成本。过滤（ Zhao, 2022 ），嵌入（ Aram, 2022 ）和打包（ Maldonado, 2022 ）是典型的特征选择技术。<br>上官璞（上官等，2020）从 EEG 数据中提取特征，应用核主成分分析进行特征降维，并利用决策树等多种算法构建了驾驶员状态检测模型。拉赫曼 M（拉赫曼，2020）使用主成分分析 PCA 结合统计数据特征提取方法，基于 t 统计检验选择合适特征，并在 SEED 公共数据集上使用人工神经网络、支持向量机和线性判别分析算法构建情绪分类模型，其中人工神经网络在依赖被试的方法中具有最高的分类准确率 86.57 ± 4.08 %。裴泽（裴，2021）基于 EEG 数据表示通道信息和通道间信息，并结合随机森林算法对负载状态进行分类，通过 F 分数方法进行特征选择后，模型的分类准确率从 83.12 % 提高到 83.47 %。黄 Jing 等（ Jing 等，未提供完整引用）, 2022) 使用卡方检验对初始提取的时间域、频率域和非线性特征进行了特征选择过程，并将显著性水平设置为 0.05 以去除总共 19 个无关特征。Parsi A (Parsi &amp; O’Callaghan, 2023) 应用了最小冗余-最大相关性方法对多个心率变异性及呼吸率特征进行特征选择，以确定检测驾驶员压力的最佳特征组合，并最终使用支持向量机算法构建了一个准确率为 87.9%、F1 分数为 86.9%的预测模型。近年来，一些研究（Chen, 2019；Yin 等, 2020；Tuncer 等, 2021；Jain 和 Jain, 2022）也利用了混合特征选择方法进行驾驶员状态检测任务。</p><h2 id="Ensemble-learning"><a href="#Ensemble-learning" class="headerlink" title="Ensemble learning"></a>Ensemble learning</h2><p>除了特征选择方法之外，集成学习方法也有助于提高模型性能（Sagi, 2018）。集成学习可以根据基础模型类型分为同质集成和异质集成。同质集成意味着集成过程中只涉及同质类型的个体学习器（Zhou, 2021），而异质集成则意味着参与集成的个体学习器是由不同的学习算法创建的（Papouskova, 2019）。常见的同质集成技术包括随机森林 RF（Probst, 2019）和 XGBoost（Chen, 2015）及其相关算法模型的一些变体，例如使用元启发式方法优化模型参数（Gupta et al., 2022, Zivkovic et al., 2022）等。Barua（Barua, 2020）利用顺序前向浮动选择（SFFS）和随机森林算法进行特征选择，使用随机森林算法构建的驾驶员认知负荷分类模型性能最佳，F1 分数达到 0.8。 昆廷·梅特耶尔（梅特耶尔，2021）使用了三种生理数据，即皮肤电活动、心率变异性以及呼吸，基于随机森林算法建立了驾驶员工作负荷模型，该模型的准确率为 95%。魏威等（魏，2023）提出了一种结合交通流量、环境以及生理信号的分析方法，用于分类驾驶员的心理负荷，结果显示，融合 ECG、EDA、环境因素以及交通流量信息构建的随机森林模型表现最佳，准确率为 97.8%。迪萨纳亚克等（迪萨纳亚克、拉贾帕克 sha、拉格尔、纳尼，2019）基于 ECG 数据提取相应的频域和时域特征，通过基数检验和递归特征消除进行特征选择，并使用集成算法如随机森林和极端随机树建立分类模型，经过特征选择后，极端随机树模型表现最佳，准确率达到 80.0%。 与之前最先进的模型相当，Jeong M（Jeong &amp; Park, 2019）建议使用一种轻量级多层随机森林（LMRF）模型来识别驾驶员的情绪状态。建议的 LMRF 模型在与现有基于深度神经网络的研究相比时表现出更优的性能。Pusarla N（Pusarla, Singh, &amp; Tripathi, 2022）使用了混合多通道 EEG 特征与网格搜索随机森林（GSRF）进行情绪状态识别，该方法从不同通道中提取 EEG 特征，所构建的分类模型在情绪公开数据集 DEAP 和 SEED 上的准确率分别为 86.3%和 97.9%。Gayathri S（Gayathri et al., 2022）基于 ECG 和 EEG 数据提取相应的特征作为模型的训练集，基于随机森林、XGBoost、LightGBM 等算法构建情绪识别模型，最终构建的情绪分类模型能够识别 9 个情绪类别，准确率为 92.5%。</p><h2 id="Motivations-and-contributions"><a href="#Motivations-and-contributions" class="headerlink" title="Motivations and contributions"></a>Motivations and contributions</h2><p>考虑到特征选择和进一步优化模型算法，以下三个问题亟待解决和考虑，以进一步提高驾驶员心理负荷和情绪状态预测的性能。1）特征的增加将大大增加模型的搜索空间。对于有限数量的训练样本，特征的增加虽然可以更好地拟合训练数据，但也可能增加模型方差并导致过拟合。2）许多机器学习算法通过某种形式的局部搜索来工作。在对训练样本进行局部搜索时，单个算法模型有可能陷入局部最优解。3）以往关于驾驶员状态检测的研究主要依赖单个算法模型，集成学习方法的应用仍然受到限制，主要依赖于同质集成（Meteier 等，2021；Barua 等，2020；Jeong 等，2019；Parui，2019）或基本的单层堆叠和投票集成方法（Fan 等，2021；Issa，2021；Kazmaier 和 van Vuuren，2022）。 在驾驶员状态检测领域，较少的研究将特征选择与集成学习相结合。<br>为了解决这些问题，本文提出了一种基于递归特征消除算法并改进了 SHAP 值的集成学习方法，用于特征选择，并考虑来自不同异构模型的最佳特征子集，同时结合多层堆叠，以提高驾驶员心理负荷和情绪状态识别的准确性。</p><p>以下是本文的主要贡献：<br>新特征选择方法：与传统的递归特征消除算法相比，基于 SHAP 值并结合 XGBoost 算法的改进递归特征消除算法可以在较少的特征组合下实现更好的模型性能，最终得到的特征子集具有更好的可解释性。</p><p>基于新型多层堆叠方法构建驾驶员状态检测模型：与单层堆叠不同，多层堆叠集成学习将基模型的输出再次与原始数据输入到下一层基模型进行训练，然后将最后一层基模型的预测结果输入元学习器重新训练，最后输出模型预测结果，这可以有效提高模型性能。</p><p>使用不同特征子集构建不同的基模型：之前构建的基于堆叠集成的驾驶员心理负荷和情绪状态识别模型使用了相同的特征子集构建不同的异构模型，但本文采用了一种集成学习方法，将不同的最优特征子集与多层堆叠相结合，在集成模型训练过程中，不同的异构模型不使用相同的特征子集。</p><p>本文剩余部分组织如下：第 2 节介绍相关基础理论，第 3 节介绍所提出的方法，第 4 节评估所构建集成模型在数据集上的性能，第 5 节总结本文并讨论未来的研究方向。</p><h1 id="Theoretical-background"><a href="#Theoretical-background" class="headerlink" title="Theoretical background"></a>Theoretical background</h1><h2 id="SHAP-values"><a href="#SHAP-values" class="headerlink" title="SHAP values"></a>SHAP values</h2><p>SHAP (SHapley Additive exPlanation)，一种受到合作博弈理论启发的加性解释模型，在近年来的可解释机器学习领域得到了广泛应用。它将输出值归因于每个特征的 SHAP 值，即计算每个特征的 SHAP 值，并相应地量化特征对最终输出值的影响。传统的特征重要性只能表明哪些特征是重要的，但不清楚每个特征是如何影响预测结果的。SHAP 值的优势在于它可以衡量特征对模型预测任务的正向或负向贡献。计算方法如式（1）所示（Lundberg &amp; Erion, 2018）。</p><h2 id="Stacking-ensemble"><a href="#Stacking-ensemble" class="headerlink" title="Stacking ensemble"></a>Stacking ensemble</h2><p>堆叠是一种元学习方法，其中基础学习器称为初级学习器，用于组合的学习器称为元学习器。堆叠首先使用原始训练集训练初级学习器，然后使用初级学习器的预测结果作为输入来训练元学习器，最后输出模型的预测结果。为了防止模型过拟合，数据通常使用 K 折交叉验证进行训练（Tang, 2014），其伪代码如算法 1 所示。</p><h2 id="Base-model"><a href="#Base-model" class="headerlink" title="Base model"></a>Base model</h2><p>本研究中使用的底层异构模型包括 XGBoost、LightGBM、CatBoost、KNN，元学习器使用 MLP（多层感知器）。</p><h1 id="Proposed-method"><a href="#Proposed-method" class="headerlink" title="Proposed method"></a>Proposed method</h1><p>本节描述了本研究提出的 RFE-SHAP 特征选择算法，以及基于不同最优特征子集的多层堆叠集成学习方法，并将所提出的方法应用于构建驾驶员状态检测模型，以评估驾驶员的心理负荷和情绪状态；整体流程架构如图 2 所示。在驾驶模拟实验中收集驾驶员的生理数据和车辆驾驶数据，提取特征，使用 XGBoost-RFE-SHAP 特征选择方法对特征进行排序，确定每个异构模型的最优特征子集，并使用每个基础模型及其对应的最优特征子集构建多层堆叠集成学习模型。</p><h2 id="RFE-SHAP-feature-selection-algorithm"><a href="#RFE-SHAP-feature-selection-algorithm" class="headerlink" title="RFE-SHAP feature selection algorithm"></a>RFE-SHAP feature selection algorithm</h2><p>在本研究中，提出了一种 RFE-SHAP 特征选择算法，RFE 算法中每个特征的重要性将通过其 SHAP 值确定，基于使用公式（1）和（2）计算不同特征下不同样本数据的 SHAP 值，并取每个样本在特征上的 SHAP 值的绝对平均值作为该特征的重要性，如公式（6）所示，其中</p><h2 id="基于不同最优特征子集的多层堆叠集成学习方法"><a href="#基于不同最优特征子集的多层堆叠集成学习方法" class="headerlink" title="基于不同最优特征子集的多层堆叠集成学习方法"></a>基于不同最优特征子集的多层堆叠集成学习方法</h2><p>如图 3 所示，本文提出了一种基于不同最优特征子集的多层堆叠集成学习方法。第一层由第 2.3 节中的众多基础模型组成，其输出被连接后输入到下一层，该层采用与第一层相同的模型类型和超参数。这种训练策略可以被视为另一种类型的深度学习，利用分层训练，“神经元”即我们使用的机器学习模型（Erickson, 2020）。</p><h2 id="Performance-evaluation-of-the-RFE-SHAP-feature-selection-algorithm"><a href="#Performance-evaluation-of-the-RFE-SHAP-feature-selection-algorithm" class="headerlink" title="Performance evaluation of the RFE-SHAP feature selection algorithm"></a>Performance evaluation of the RFE-SHAP feature selection algorithm</h2><p>特征选择是指从原始数据特征集合中选择一个目标子集，以承载对工作任务影响最大的信息。特征选择是一个多目标优化任务，旨在用尽可能少的特征组合获得更好的模型性能。<br>数据集按照 7:3 的比例划分为训练集和测试集。基于训练数据，结合 XGBoost 提出的 RFE-SHAP 算法被用于初始提取特征的选择。图 5 展示了对驾驶员正常-低负荷状态影响最大的 10 个特征，图中的每个点代表一个样本，颜色表示特征值（红色表示高，蓝色表示低）。基于 SHAP 输出的模型特征重要性不仅反映了特征影响的大小，还反映了特征对预测的正向和负向影响，从而增强了模型的可解释性。<br>不同的最优特征子集被用于集成堆叠中使用的异构模型，获得的结果见表 3。除了 LightGBM 模型外，XGBoost-RFE-SHAP 算法在比常规 XGBoost-RFE 算法更少的特征组合下实现了更好的模型性能。即使两种特征选择方法为 LightGBM 模型获得的最优特征子集数量相同，XGBoost-RFE-SHAP 算法选择的最优特征子集也能实现更好的模型性能。经过特征选择后，XGBoost 在基模型中表现最佳，准确率为 93.16%。与基于传统 XGBoost-RFE 算法进行特征选择相比，基于 XGBoost-RFE-SHAP 算法进行特征选择时，KNN 模型表现出最高的性能提升，其模型分类准确率提高了 0.37 个百分点。从计算开销的角度来看，RFE-SHAP 算法的计算开销高于传统的 RFE 算法。 在实验数据集上，两种算法分别运行 50 次，RFE-SHAP 算法的平均计算时间约为 RFE 算法的 1.3 倍。实验中使用的计算机处理器为 Intel(R) Core(TM) i5-10500 <a href="mailto:&#67;&#80;&#85;&#x40;&#x33;&#46;&#x31;&#48;">&#67;&#80;&#85;&#x40;&#x33;&#46;&#x31;&#48;</a> GHz，运行内存为 16 GB，计算机系统为 Windows10。</p><h2 id="Performance-evaluation-of-integrated-models"><a href="#Performance-evaluation-of-integrated-models" class="headerlink" title="Performance evaluation of integrated models"></a>Performance evaluation of integrated models</h2><p>为了检测驾驶员的心理负荷和情绪状态，在这一部分利用基于多种最优特征子集混合的多层堆叠的集成学习技术创建了驾驶员状态检测模型。图 6 展示了该模型的混淆矩阵，模型的最终准确率为 97.48%，F1 分数为 97.47%，精确率为 97.48%，召回率为 97.47%，MCC 为 0.9712，Jaccard 分数为 0.9507，AUC 为 0.9991。</p><h2 id="Comparison-with-the-single-base-model"><a href="#Comparison-with-the-single-base-model" class="headerlink" title="Comparison with the single base model"></a>Comparison with the single base model</h2><p>构建的集成模型（Proposed-Method）与单一基模进行比较。除了常用的评估指标如准确率、精确率、召回率、F1 分数、MCC 和 Jaccard 系数外，本文还使用 Cohen’s kappa 系数和 McNemar 检验来评估分类算法的性能，如表 4 所示。<br><img src="https://oss-liuchengtu.hudunsoft.com/userimg/be/be223fb0c5fc38f3eec1d215623d47ff.png"></p><h2 id="Comparison-with-heterogeneous-integration-methods"><a href="#Comparison-with-heterogeneous-integration-methods" class="headerlink" title="Comparison with heterogeneous integration methods"></a>Comparison with heterogeneous integration methods</h2><p>在驾驶员心理负荷和情绪状态识别领域，常用的机器学习算法有：决策树（DT）、支持向量机（SVM）、随机森林（RF）、AdaBoost 和梯度提升树（GBDT）（McDonald 等，2020；Zepf 等，2020；He 等，2022）。表 6 展示了所构建集成学习模型（Proposed-Method）与常用算法模型的对比结果。在构建的 DT、SVM、RF、AdaBoost 和 GBDT 模型中，RF 模型表现最佳，准确率为 93.24%，F1 分为 93.24%，精确率为 93.31%，召回率为 93.21%，MCC 为 0.9228，Jaccard 分为 0.8734，κ值为 0.9227。与常用的其他算法模型相比，本研究基于不同最优特征子集构建的多层堆叠集成模型表现更好。此外，McNemar 检验结果表明，所提出的方法显著优于常用机器学习算法的模型。</p></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/paper/">paper</a><a class="post-meta__tags" href="/tags/model/">model</a><a class="post-meta__tags" href="/tags/traffic-risk/">traffic_risk</a></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/12/26/SHAP-RFE-%E5%8E%9F%E7%90%86/" title="SHAP-RFE-原理"><img class="cover" src="https://markdown.liuchengtu.com/work/uploads/upload_70799a923ad02a4ce78cd43496335582.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">SHAP-RFE-原理</div></div></a></div><div class="next-post pull-right"><a href="/2024/12/16/CICIP-2025/" title="CICIP-2025"><img class="cover" src="https://markdown.liuchengtu.com/work/uploads/upload_d0e0643ae6e6d31aa47a1110b735c53e.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">CICIP-2025</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/07/22/A%20traffic%20dynamic%20operation%20risk%20assessment%20method%20using%20driving%20behaviors%20and%20traffic%20flow%20DataAn%20empirical%20analysis/" title="A traffic dynamic operation risk assessment method using driving behaviors and traffic flow Data:An empirical analysis"><img class="cover" src="https://markdown.liuchengtu.com/work/uploads/upload_e804024b0c69290f4c4b80fc186b66ef.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-22</div><div class="title">A traffic dynamic operation risk assessment method using driving behaviors and traffic flow Data:An empirical analysis</div></div></a></div><div><a href="/2024/07/23/Data-unbalanced%20traffic%20accident%20prediction%20via%20adaptive%20graph%20and%20self-supervised%20learning-%E5%9F%BA%E4%BA%8E%E8%87%AA%E9%80%82%E5%BA%94%E5%9B%BE%E5%92%8C%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1%E4%BA%A4%E9%80%9A%E4%BA%8B%E6%95%85%E9%A2%84%E6%B5%8B/" title="Data-unbalanced traffic accident prediction via adaptive graph and self-supervised learning-基于自适应图和自监督学习的数据不平衡交通事故预测"><img class="cover" src="https://markdown.liuchengtu.com/work/uploads/upload_3baee12636bda38067ea637df63a95bc.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-23</div><div class="title">Data-unbalanced traffic accident prediction via adaptive graph and self-supervised learning-基于自适应图和自监督学习的数据不平衡交通事故预测</div></div></a></div><div><a href="/2024/07/25/Driving%20Risk%20Identification%20of%20Truck%20Drivers%20Based%20on%20China%E2%80%99s%20Highway%20Toll%20Data/" title="Driving Risk Identification of Truck Drivers Based on China’s Highway Toll Data"><img class="cover" src="https://markdown.liuchengtu.com/work/uploads/upload_3dd1e3443dc8b8bc8ed820288c9c3436.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-25</div><div class="title">Driving Risk Identification of Truck Drivers Based on China’s Highway Toll Data</div></div></a></div><div><a href="/2024/07/23/Machine%20learning%20based%20real-time%20prediction%20of%20freeway%20crash%20risk%20using%20crowdsourced%20probe%20vehicle%20data-%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AB%98%E9%80%9F%E5%85%AC%E8%B7%AF%E7%A2%B0%E6%92%9E%E9%A3%8E%E9%99%A9%E5%AE%9E%E6%97%B6%E9%A2%84%E6%B5%8B%EF%BC%8C%E4%BD%BF%E7%94%A8%E4%BC%97%E5%8C%85%E6%8E%A2%E6%B5%8B%E8%BD%A6%E8%BE%86%E6%95%B0%E6%8D%AE/" title="Machine learning based real-time prediction of freeway crash risk using crowdsourced probe vehicle data-基于机器学习的高速公路碰撞风险实时预测，使用众包探测车辆数据"><img class="cover" src="https://markdown.liuchengtu.com/work/uploads/upload_39fe147b88956271f082f81a5b97ff17.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-23</div><div class="title">Machine learning based real-time prediction of freeway crash risk using crowdsourced probe vehicle data-基于机器学习的高速公路碰撞风险实时预测，使用众包探测车辆数据</div></div></a></div><div><a href="/2024/07/22/Traffic%20accident%20severity%20prediction%20with%20ensemble%20learning%20methods-%E5%9F%BA%E4%BA%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%A4%E9%80%9A%E4%BA%8B%E6%95%85%E4%B8%A5%E9%87%8D%E7%A8%8B%E5%BA%A6%E9%A2%84%E6%B5%8B/" title="Traffic accident severity prediction with ensemble learning methods-基于集成学习方法的交通事故严重程度预测"><img class="cover" src="https://markdown.liuchengtu.com/work/uploads/upload_3e8f8c20a64833d257bb36f8e111cd5e.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-22</div><div class="title">Traffic accident severity prediction with ensemble learning methods-基于集成学习方法的交通事故严重程度预测</div></div></a></div><div><a href="/2024/03/01/example/" title="风险预测指标体系"><img class="cover" src="https://markdown.liuchengtu.com/work/uploads/upload_74a76488804fc93b0bb2fa230cb42694.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-01</div><div class="title">风险预测指标体系</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2023/12/07/gbAJ49c5PmNiRUu.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">Gurongi</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">83</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">70</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://www.google.com/" target="_blank" title="Goole"><i class="fab fa-brands fa-google" style="color:f8f9d8"></i></a><a class="social-icon" href="https://scholar.google.com/" target="_blank" title="Portal"><i class="fab fa-google-scholar" style="color:#24292e"></i></a><a class="social-icon" href="https://www.zhihu.com/" target="_blank" title="Zhihu"><i class="fas fa-brands fa-zhihu" style="color:#4a7dbe"></i></a><a class="social-icon" href="https://www.gamer520.com/" target="_blank" title="Game"><i class="fas fa-brands fa-playstation" style="color:#4a7dbe"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%95%E6%96%87"><span class="toc-number">1.</span> <span class="toc-text">引文</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%9F%E5%88%8A"><span class="toc-number">2.</span> <span class="toc-text">期刊</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">3.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-number">4.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Feature-selection"><span class="toc-number">4.1.</span> <span class="toc-text">Feature selection</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ensemble-learning"><span class="toc-number">4.2.</span> <span class="toc-text">Ensemble learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivations-and-contributions"><span class="toc-number">4.3.</span> <span class="toc-text">Motivations and contributions</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Theoretical-background"><span class="toc-number">5.</span> <span class="toc-text">Theoretical background</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SHAP-values"><span class="toc-number">5.1.</span> <span class="toc-text">SHAP values</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Stacking-ensemble"><span class="toc-number">5.2.</span> <span class="toc-text">Stacking ensemble</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Base-model"><span class="toc-number">5.3.</span> <span class="toc-text">Base model</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Proposed-method"><span class="toc-number">6.</span> <span class="toc-text">Proposed method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#RFE-SHAP-feature-selection-algorithm"><span class="toc-number">6.1.</span> <span class="toc-text">RFE-SHAP feature selection algorithm</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%B8%8D%E5%90%8C%E6%9C%80%E4%BC%98%E7%89%B9%E5%BE%81%E5%AD%90%E9%9B%86%E7%9A%84%E5%A4%9A%E5%B1%82%E5%A0%86%E5%8F%A0%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="toc-number">6.2.</span> <span class="toc-text">基于不同最优特征子集的多层堆叠集成学习方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Performance-evaluation-of-the-RFE-SHAP-feature-selection-algorithm"><span class="toc-number">6.3.</span> <span class="toc-text">Performance evaluation of the RFE-SHAP feature selection algorithm</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Performance-evaluation-of-integrated-models"><span class="toc-number">6.4.</span> <span class="toc-text">Performance evaluation of integrated models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Comparison-with-the-single-base-model"><span class="toc-number">6.5.</span> <span class="toc-text">Comparison with the single base model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Comparison-with-heterogeneous-integration-methods"><span class="toc-number">6.6.</span> <span class="toc-text">Comparison with heterogeneous integration methods</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/12/26/SHAP-RFE-%E5%8E%9F%E7%90%86/" title="SHAP-RFE-原理"><img src="https://markdown.liuchengtu.com/work/uploads/upload_70799a923ad02a4ce78cd43496335582.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="SHAP-RFE-原理"></a><div class="content"><a class="title" href="/2024/12/26/SHAP-RFE-%E5%8E%9F%E7%90%86/" title="SHAP-RFE-原理">SHAP-RFE-原理</a><time datetime="2024-12-26T15:59:59.000Z" title="发表于 2024-12-26 23:59:59">2024-12-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/22/A%20multilayer%20stacking%20method%20base%20on%20RFE-SHAP%20feature%20selection%20strategy%20for%20recognition%20of%20driver%E2%80%99s%20mental%20load%20and%20emotional%20state/" title="A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state"><img src="https://markdown.liuchengtu.com/work/uploads/upload_7c23db75dbf070c18ce49f88730a1aff.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state"></a><div class="content"><a class="title" href="/2024/12/22/A%20multilayer%20stacking%20method%20base%20on%20RFE-SHAP%20feature%20selection%20strategy%20for%20recognition%20of%20driver%E2%80%99s%20mental%20load%20and%20emotional%20state/" title="A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state">A multilayer stacking method base on RFE-SHAP feature selection strategy for recognition of driver’s mental load and emotional state</a><time datetime="2024-12-22T15:59:59.000Z" title="发表于 2024-12-22 23:59:59">2024-12-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/16/CICIP-2025/" title="CICIP-2025"><img src="https://markdown.liuchengtu.com/work/uploads/upload_d0e0643ae6e6d31aa47a1110b735c53e.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="CICIP-2025"></a><div class="content"><a class="title" href="/2024/12/16/CICIP-2025/" title="CICIP-2025">CICIP-2025</a><time datetime="2024-12-16T15:59:59.000Z" title="发表于 2024-12-16 23:59:59">2024-12-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/15/%E4%BA%8B%E6%95%85%E6%97%B6%E9%97%B4%E7%AD%9B%E9%80%89%E7%AE%97%E6%B3%95%E6%9B%B4%E6%96%B0/" title="事故时间筛选算法更新"><img src="https://markdown.liuchengtu.com/work/uploads/upload_878f997b95c39114d231c0dbf849b1b2.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="事故时间筛选算法更新"></a><div class="content"><a class="title" href="/2024/12/15/%E4%BA%8B%E6%95%85%E6%97%B6%E9%97%B4%E7%AD%9B%E9%80%89%E7%AE%97%E6%B3%95%E6%9B%B4%E6%96%B0/" title="事故时间筛选算法更新">事故时间筛选算法更新</a><time datetime="2024-12-15T02:13:00.000Z" title="发表于 2024-12-15 10:13:00">2024-12-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/12/06/Sustainability%E6%8A%95%E7%A8%BF/" title="Sustainability投稿"><img src="https://markdown.liuchengtu.com/work/uploads/upload_e804024b0c69290f4c4b80fc186b66ef.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Sustainability投稿"></a><div class="content"><a class="title" href="/2024/12/06/Sustainability%E6%8A%95%E7%A8%BF/" title="Sustainability投稿">Sustainability投稿</a><time datetime="2024-12-06T02:52:51.000Z" title="发表于 2024-12-06 10:52:51">2024-12-06</time></div></div></div></div></div></div></main><footer id="footer" style="background:0 0"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By Gurongi</div><div class="footer_custom_text"><div id="runtime"></div></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script defer id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div></body></html>